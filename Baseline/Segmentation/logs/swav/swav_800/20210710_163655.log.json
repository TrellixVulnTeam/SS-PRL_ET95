{"env_info": "sys.platform: linux\nPython: 3.6.13 |Anaconda, Inc.| (default, Feb 23 2021, 21:15:04) [GCC 7.3.0]\nCUDA available: True\nGPU 0,1,2,3: NVIDIA Tesla V100-SXM2-32GB\nCUDA_HOME: /usr/local/cuda-9.2\nNVCC: Cuda compilation tools, release 9.2, V9.2.148\nGCC: gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-28)\nPyTorch: 1.4.0+cu92\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - Intel(R) Math Kernel Library Version 2019.0.4 Product Build 20190411 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CUDA Runtime 9.2\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_37,code=compute_37\n  - CuDNN 7.6.3\n  - Magma 2.5.1\n  - Build settings: BLAS=MKL, BUILD_NAMEDTENSOR=OFF, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Wno-stringop-overflow, DISABLE_NUMA=1, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n\nTorchVision: 0.5.0+cu92\nOpenCV: 4.5.2\nMMCV: 1.1.5\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 9.2\nMMSegmentation: 0.11.0+0b2c438", "seed": null, "exp_name": "fcn_r50-d8_512x512_20k_voc12aug.py"}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.00998, "memory": 20165, "data_time": 0.00408, "decode.loss_seg": 1.67325, "decode.acc_seg": 52.91234, "aux.loss_seg": 0.6979, "aux.acc_seg": 52.41953, "loss": 2.37115, "time": 0.64964}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 0.00996, "memory": 20165, "data_time": 0.00454, "decode.loss_seg": 1.48237, "decode.acc_seg": 55.01308, "aux.loss_seg": 0.59016, "aux.acc_seg": 55.09874, "loss": 2.07253, "time": 0.39991}
{"mode": "train", "epoch": 1, "iter": 150, "lr": 0.00993, "memory": 20165, "data_time": 0.0048, "decode.loss_seg": 1.54407, "decode.acc_seg": 53.61339, "aux.loss_seg": 0.61669, "aux.acc_seg": 54.02338, "loss": 2.16076, "time": 0.40146}
{"mode": "train", "epoch": 1, "iter": 200, "lr": 0.00991, "memory": 20165, "data_time": 0.00498, "decode.loss_seg": 1.4648, "decode.acc_seg": 54.41272, "aux.loss_seg": 0.58809, "aux.acc_seg": 54.34759, "loss": 2.05288, "time": 0.40163}
{"mode": "train", "epoch": 1, "iter": 250, "lr": 0.00989, "memory": 20165, "data_time": 0.00482, "decode.loss_seg": 1.5378, "decode.acc_seg": 52.66611, "aux.loss_seg": 0.61905, "aux.acc_seg": 52.80078, "loss": 2.15685, "time": 0.40148}
{"mode": "train", "epoch": 1, "iter": 300, "lr": 0.00987, "memory": 20165, "data_time": 0.00474, "decode.loss_seg": 1.45736, "decode.acc_seg": 55.22034, "aux.loss_seg": 0.58473, "aux.acc_seg": 55.25309, "loss": 2.04209, "time": 0.40001}
{"mode": "train", "epoch": 1, "iter": 350, "lr": 0.00984, "memory": 20165, "data_time": 0.00471, "decode.loss_seg": 1.45546, "decode.acc_seg": 54.74695, "aux.loss_seg": 0.58779, "aux.acc_seg": 54.62987, "loss": 2.04325, "time": 0.39916}
{"mode": "train", "epoch": 1, "iter": 400, "lr": 0.00982, "memory": 20165, "data_time": 0.0046, "decode.loss_seg": 1.43407, "decode.acc_seg": 54.26324, "aux.loss_seg": 0.57885, "aux.acc_seg": 54.42728, "loss": 2.01291, "time": 0.4006}
